{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "\n",
    "from evaluation.metric_semantic_evaluation import MeshEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL PATHS BELOW\n",
    "artifacts_path = \"/home/tonirv/Documents/uHumans2_VIO_vxblx/\"\n",
    "gt_meshes_path = \"/home/tonirv/datasets/uHumans2/uHumans dataset V2.0 GT Meshes/\"\n",
    "\n",
    "semantic_labels_csvs_path = \"/home/tonirv/Code/ROS/kimera_ws/src/Kimera-Semantics/kimera_semantics_ros/cfg/\"\n",
    "visualize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mesh_evaluation(scene_type, human_size, number_of_mesh_samples):\n",
    "    est_mesh_base_path = artifacts_path + \"/{}_scene/uHumans2_{}_s1_{}h/\".format(scene_type, scene_type, human_size)\n",
    "    est_mesh_names = [\n",
    "      #'mesh_DVIO.ply', \n",
    "      #'mesh_gt.ply', \n",
    "      #'mesh_DVIO_wo_DM.ply', \n",
    "      #'mesh_gt_wo_DM.ply',\n",
    "        'mesh_pgmo.ply'\n",
    "    ]\n",
    "    \n",
    "    # Parallelize! Write output to file?\n",
    "    for est_mesh_name in est_mesh_names:\n",
    "        est_mesh_path = est_mesh_base_path + est_mesh_name\n",
    "        print(\"EVAL: {} in {} scene\".format(est_mesh_name, scene_type))\n",
    "        if not os.path.exists(est_mesh_path):\n",
    "            print(\"Path to {} doesn't exist: {}\".format(est_mesh_name, est_mesh_path))\n",
    "            continue\n",
    "            \n",
    "        mesh_eval = MeshEvaluator(est_mesh_path, gt_mesh_path, semantic_labels_csv_path, visualize)\n",
    "        \n",
    "        only_geometric_eval = False\n",
    "        #if \"_\" in est_mesh_name:\n",
    "            # Only compute geometric erros if comparing with vs wo DM.\n",
    "        #    only_geometric_eval = True\n",
    "        \n",
    "        inlier_rmse, semantic_accuracy = mesh_eval.compare_meshes(number_of_mesh_samples, only_geometric_eval)\n",
    "        \n",
    "        print(\"Inlier RMSE [m]: \", inlier_rmse)\n",
    "        print(\"Semantic Accuracy [%]: \", semantic_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartment Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mesh_path = gt_meshes_path + \"apartment.ply\"\n",
    "semantic_labels_csv_path = semantic_labels_csvs_path + \"tesse_multiscene_archviz1_segmentation_mapping.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartment S1 00h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in apartment scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 1.000000, inlier_rmse = 0.060650, and correspondence_set size of 525816\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.0592510698435\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e47f7d90eb400b9165e665455eb935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=525816.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "65.1345717894\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.05925106984346204)\n",
      "('Semantic Accuracy [%]: ', 65.1345717893712)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"apartment\", \"00\", 10000000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartment S1 01h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in apartment scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 1.000000, inlier_rmse = 0.079410, and correspondence_set size of 753258\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.0786782510678\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f652b80a054c26901c8176dc42f1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=753258.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "65.1418239169\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.07867825106784151)\n",
      "('Semantic Accuracy [%]: ', 65.14182391690497)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"apartment\", \"01\", 10000000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartment S1 02h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in apartment scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 1.000000, inlier_rmse = 0.079348, and correspondence_set size of 753258\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.0786282902416\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9389c3f930a04d15a21af9c8ce760a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=753258.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "65.3791927865\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.07862829024162833)\n",
      "('Semantic Accuracy [%]: ', 65.37919278653528)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"apartment\", \"02\", 10000000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Office Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mesh_path = gt_meshes_path + \"office.ply\"\n",
    "semantic_labels_csv_path = semantic_labels_csvs_path + \"tesse_multiscene_office2_segmentation_mapping.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Office Scene 00h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in office scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 1.000000, inlier_rmse = 0.127551, and correspondence_set size of 3222658\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.119658125264\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8eeab6653b46f7a510305a42c5d196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3222658.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15.8278042535\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.11965812526365766)\n",
      "('Semantic Accuracy [%]: ', 15.827804253507507)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"office\", \"00\", 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Office Scene 06h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in office scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 1.000000, inlier_rmse = 0.098618, and correspondence_set size of 3276133\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.0980076977455\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ced31103d92465abfe9c09fd66057df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3276133.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16.3362415384\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.09800769774550291)\n",
      "('Semantic Accuracy [%]: ', 16.3362415384235)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"office\", \"06\", 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Office Scene 12h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in office scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 1.000000, inlier_rmse = 0.149876, and correspondence_set size of 3283192\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.148178042934\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15712cf7052e43e28c0a9a707538d7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3283192.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15.9802107218\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.1481780429342038)\n",
      "('Semantic Accuracy [%]: ', 15.980210721761019)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"office\", \"12\", 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nieghborhood Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mesh_path = gt_meshes_path + \"neighborhood.ply\"\n",
    "semantic_labels_csv_path = semantic_labels_csvs_path + \"tesse_multiscene_neighborhood1_segmentation_mapping.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nieghborhood Scene 00h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in neighborhood scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 0.870790, inlier_rmse = 0.095196, and correspondence_set size of 2410314\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.0939997219214\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802e0320263249f0876d63288e8c1b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2410644.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "93.2923733243\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.09399972192138618)\n",
      "('Semantic Accuracy [%]: ', 93.2923733243067)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"neighborhood\", \"00\", 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nieghborhood Scene 24h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in neighborhood scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 0.878644, inlier_rmse = 0.110074, and correspondence_set size of 3700683\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.110989672256\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90a17892a004230bc27568b9d2903b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3701731.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "93.7398746694\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.11098967225585564)\n",
      "('Semantic Accuracy [%]: ', 93.73987466944519)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"neighborhood\", \"24\", 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nieghborhood Scene 36h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in neighborhood scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 0.877785, inlier_rmse = 0.500208, and correspondence_set size of 3798408\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.430754232426\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ba901f708841e69f3c3700a6112749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3807675.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "81.2263126449\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.4307542324255425)\n",
      "('Semantic Accuracy [%]: ', 81.22631264485545)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"neighborhood\", \"36\", 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subway Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mesh_path = gt_meshes_path + \"subway.ply\"\n",
    "semantic_labels_csv_path = semantic_labels_csvs_path + \"tesse_multiscene_underground1_segmentation_mapping.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subway Scene 00h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in subway scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 0.996456, inlier_rmse = 0.437874, and correspondence_set size of 3846012\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.263362253445\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614c685ec7574af7b3cd3b1757a01fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3840632.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "89.302724135\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.26336225344463693)\n",
      "('Semantic Accuracy [%]: ', 89.30272413498612)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"subway\", \"00\", 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subway Scene 24h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in subway scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 0.990485, inlier_rmse = 0.381587, and correspondence_set size of 4162226\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.31648076465\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d92dc238b844c0d874b2105d968efa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4149739.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "86.2847518844\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.3164807646504608)\n",
      "('Semantic Accuracy [%]: ', 86.28475188439562)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"subway\", \"24\", 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subway Scene 36h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: mesh_pgmo.ply in subway scene\n",
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 0.978984, inlier_rmse = 0.460923, and correspondence_set size of 4290305\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Done with point-to-point ICP\n",
      "Geometric inlier RMSE [m]: \n",
      "0.389654062741\n",
      " \n",
      "Calculating Semantic Accuracy...\n",
      "Semantic Accuracy [%]: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da56157aa7c248bd9bdbcb9ce4d48291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4290492.0), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "82.8048624726\n",
      " \n",
      "('Inlier RMSE [m]: ', 0.3896540627407281)\n",
      "('Semantic Accuracy [%]: ', 82.80486247264882)\n"
     ]
    }
   ],
   "source": [
    "run_mesh_evaluation(\"subway\", \"36\", 1000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
