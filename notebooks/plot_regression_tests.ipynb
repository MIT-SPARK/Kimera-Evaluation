{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Logger' object has no attribute 'hasHandlers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-33eb57b94e6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(levelname)s - %(message)s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# add the handlers to the logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasHandlers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Logger' object has no attribute 'hasHandlers'"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import logging\n",
    "import pprint\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import psutil\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.INFO)\n",
    "log.propagate = False\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "# create formatter and add it to the handlers\n",
    "ch.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))\n",
    "# add the handlers to the logger\n",
    "if (log.hasHandlers()):\n",
    "    log.handlers.clear()\n",
    "log.addHandler(ch)\n",
    "# \"application\" code\n",
    "log.debug(\"debug message\")\n",
    "log.info(\"info message\")\n",
    "log.warn(\"warn message\")\n",
    "log.error(\"error message\")\n",
    "log.critical(\"critical message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse experiment yaml file\n",
    "experiments_path=\"../experiments/regression_test.yaml\"\n",
    "\n",
    "# Get experiment information from yaml file.\n",
    "experiment_params = yaml.load(open(experiments_path))\n",
    "\n",
    "regression_tests_dir = os.path.expandvars(experiment_params['regression_tests_dir'])\n",
    "params_dir = os.path.expandvars(experiment_params['params_dir'])\n",
    "dataset_dir = os.path.expandvars(experiment_params['dataset_dir'])\n",
    "executable_path = os.path.expandvars(experiment_params['executable_path'])\n",
    "\n",
    "datasets_to_run = experiment_params['datasets_to_run']\n",
    "regression_params = experiment_params['regression_parameters']\n",
    "\n",
    "# Build dictionary from parameter name to list of parameter values\n",
    "param_name_to_values = dict()\n",
    "for regression_param in regression_params:\n",
    "    param_name_to_values[regression_param['name']] = regression_param['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve stats, if they are not there, try to collect them:\n",
    "full_stats_path = os.path.join(regression_tests_dir, \"all_stats.yaml\")\n",
    "stats = dict()\n",
    "if os.path.isfile(full_stats_path):\n",
    "    log.info(\"Found existent stats. Opening full stats from:\" + full_stats_path)\n",
    "    stats = yaml.load(open(full_stats_path))\n",
    "else:\n",
    "    log.info(\"Collecting full stats.\")\n",
    "    # Collect all yaml results for a given parameter name:\n",
    "    for regression_param in regression_params:\n",
    "        # Redirect to param_name_value dir param_name = regression_param['name']\n",
    "        param_name = regression_param['name']\n",
    "        stats[param_name] = dict()\n",
    "        for param_value in regression_param['values']:\n",
    "            results_dir = os.path.join(regression_tests_dir, param_name, str(param_value))\n",
    "            # Redirect to modified params_dir\n",
    "            params_dir = os.path.join(results_dir, 'params')\n",
    "            stats[param_name][param_value] = dict()\n",
    "            for dataset in datasets_to_run:\n",
    "                dataset_name = dataset['name']\n",
    "                pipelines_to_run = dataset['pipelines']\n",
    "                stats[param_name][param_value][dataset_name] = dict()\n",
    "                for pipeline in pipelines_to_run:\n",
    "                    results_file = os.path.join(results_dir, dataset_name, pipeline, \"results.yaml\")\n",
    "                    if os.path.isfile(results_file):\n",
    "                        stats[param_name][param_value][dataset_name][pipeline] = yaml.load(open(results_file,'r'))\n",
    "                    else:\n",
    "                        log.warning(\"Could not find results file: {}. Adding cross to boxplot...\".format(results_file))\n",
    "                        stats[param_name][param_value][dataset_name][pipeline] = False\n",
    "\n",
    "    # Save all stats in regression tests root directory for future usage.\n",
    "    with open(full_stats_path, 'w') as outfile:\n",
    "        outfile.write(yaml.dump(stats))\n",
    "    \n",
    "    # Push to the cloud?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display plots for that result\n",
    "# pprint.pprint(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot(x_data, y_data):\n",
    "    colors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)', 'rgba(44, 160, 101, 0.5)',\n",
    "              'rgba(255, 65, 54, 0.5)', 'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)']\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for xd, yd in zip(x_data, y_data):\n",
    "            fig.add_trace(go.Box(\n",
    "                y=yd,\n",
    "                name=xd,\n",
    "                boxpoints='all',\n",
    "                jitter=0.5,\n",
    "                whiskerwidth=0.2,\n",
    "                marker_size=2,\n",
    "                line_width=1)\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Parameter: ' + param_name + ', dataset: ' + dataset_name,\n",
    "        yaxis=dict(\n",
    "            autorange=True,\n",
    "            showgrid=True,\n",
    "            zeroline=True,\n",
    "            dtick=5,\n",
    "            gridcolor='rgb(255, 255, 255)',\n",
    "            gridwidth=1,\n",
    "            zerolinecolor='rgb(255, 255, 255)',\n",
    "            zerolinewidth=2,\n",
    "        ),\n",
    "        margin=dict(\n",
    "            l=40,\n",
    "            r=30,\n",
    "            b=80,\n",
    "            t=100,\n",
    "        ),\n",
    "        paper_bgcolor='rgb(243, 243, 243)',\n",
    "        plot_bgcolor='rgb(243, 243, 243)',\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "def plot2():\n",
    "    colors = ['#3D9970',  '#FF4136', '#FF851B']\n",
    "    \n",
    "    names = ['S', 'SP', 'SPR']\n",
    "    \n",
    "    x_data = [1, 1, 1, 1, 1, 1,\n",
    "              2, 2, 2, 2, 2, 2]\n",
    "    \n",
    "    y_data= [[0.2, 0.2, 0.6, 1.0, 0.5, 0.4, 0.2, 0.7, 0.9, 0.1, 0.5, 0.3],\n",
    "            [0.6, 0.7, 0.3, 0.6, 0.0, 0.5, 0.7, 0.9, 0.5, 0.8, 0.7, 0.2],\n",
    "            [0.1, 0.3, 0.1, 0.9, 0.6, 0.6, 0.9, 1.0, 0.3, 0.6, 0.8, 0.5]]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for i in xrange(len(names)):\n",
    "        fig.add_trace(go.Box(\n",
    "            y=y_data[i],\n",
    "            x=x_data,\n",
    "            name=names[i],\n",
    "            marker_color=colors[i]\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        yaxis_title='ATE errors',\n",
    "        boxmode='group' # group together boxes of the different traces for each value of x\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store stats in a tidy Pandas DataFrame # TODO(Toni): this should be done in the evaluation_lib.py script...\n",
    "stats_list = []\n",
    "for param_name in stats:\n",
    "    for param_value in stats[param_name]:\n",
    "        for dataset_name in stats[param_name][param_value]:\n",
    "            for pipeline in stats[param_name][param_value][dataset_name]:\n",
    "                result = stats[param_name][param_value][dataset_name][pipeline]\n",
    "                if result != False:\n",
    "                    result = result['absolute_errors'].np_arrays['error_array']\n",
    "                    stats_list.append([param_name, param_value, dataset_name, pipeline, result])\n",
    "\n",
    "df = pd.DataFrame.from_records(stats_list)\n",
    "df.columns = ['Param Name', 'Param Value', 'Dataset Name', 'Pipe Type', 'ATE errors']\n",
    "df.set_index(['Param Name', 'Dataset Name'], inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def boxplot(param_name, dataset_name, tidy):\n",
    "    tidy.set_index(['Param Value', 'Pipe Type'], inplace = True)\n",
    "    tidy_2 = tidy['ATE errors'].apply(lambda x: pd.Series(x)).stack().reset_index(level=2, drop=True).to_frame('ATE errors')\n",
    "    tidy_2.reset_index(level=['Pipe Type', 'Param Value'], drop=False, inplace=True)\n",
    "    tidy_2.rename(columns={'Param Value': param_name}, inplace=True)\n",
    "    fig = px.box(tidy_2, x=param_name, y=\"ATE errors\", points=\"all\", color=\"Pipe Type\")\n",
    "\n",
    "    fig.update_layout(\n",
    "    title=go.layout.Title(\n",
    "        text=\"Dataset: \" + dataset_name\n",
    "    ),\n",
    "    xaxis=go.layout.XAxis(\n",
    "        title=go.layout.xaxis.Title(\n",
    "            text=param_name\n",
    "        )\n",
    "    ),\n",
    "    yaxis=go.layout.YAxis(\n",
    "        title=go.layout.yaxis.Title(\n",
    "            text=\"ATE [m]\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    #plotly.offline.plot(fig, filename='regression_test_' + dataset_name + '_' + param_name + '.html')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate figures\n",
    "figures = [boxplot(x, y, df.loc[x].loc[y]) for x in df.index.levels[0] for y in df.index.levels[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show figures\n",
    "for figure in figures:\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.orca.status\n",
    "plotly.io.orca.config.executable = 'venv/bin/orca-server'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save figures\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.mkdir(\"figures\")\n",
    "\n",
    "#for figure in figures:\n",
    "#    figure.write_image(\"figures/\"+ figure.layout.title.text + \".svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
